#start-all.sh, stop-all.sh
#REST API를 사용하기 위해서는 hdfs-site.xml에 다음의 설정이 되어 있어야 합니다.
 <name>dfs.webhdfs.enabled</name>
    <value>true</value>

        <property>
            <name>dfs.permissions.enabled</name>
            <value>false</value>
        </property>

#서비스 상태를 조회하기 위해 hdfs 커맨드의 haadmin 옵션을 활용
hdfs haadmin -getAllServiceState 

#master01 stanby 상태 -> active 상태로
hdfs haadmin -transitionToActive NN1 --forcemanual 

# 폴더 생성
hdfs dfs -mkdir /data
hdfs dfs -mkdir /data/weather

# 서버 host 공개 ip로 설정해줘야함
54.180.83.185  master01
54.180.159.210 master02

#k8s master서버에 추가해줘야함(hdfs 서버 ip, host명 정보들)

---------------------------------------------

# kafka : 대용량 실시간 메세징 시스템 (?)
# 대용량의 데이터, 트래픽을 안정적이고 빠르게 처리하는 데 사용.
# 이를 위해 아파치 카프카는 분산형 아키텍처를 채택하며, 여러 대의 브로커와 프로듀서, 컨슈머로 구성됩니다.
# PublishKafka_2_0 Kafka Producer에 해당하는 부분입니다. Upstream에서 받은 Contents를 메세지로 BrokerServer로 전송합니다.
# ConsumerKafka_2_0 Kafka의 Consumer 프로세서입니다. Producer가 생성한 메세지를 받게 됩니다.
# 포르듀서가 새로운 메시지를 카프카로 보냄
# 프로듀서가 보낸 메시지는 카프카에 컨슈머 큐(카프카 기준 토픽-식별자-)에 도착해 저장됨
# 컨슈머는 카프카 서버에 접속해 새로운 메시지 가져감
# 브로커 : 카프카 애플리케이션이 설치되어 있는 서버 또는 노드라고 부른다..? 오호..
# 토픽 : 메시지 그룹. 프로듀서와 컨슈머들이 카프카로 보낸 자신들의 메시지를 구분하기 위한 이름으로 사용함. 많은 수의 프로듀서, 컨슈머들이 동일한 카프카를 이용하게 된다면 메시지들이 서로 뒤섞여 각자 원하는 메시지를 얻기가 어려워짐. 그래서 토픽이라는 이름으로 구분해서 사용

# 카프카를 써야하는 이유?
# 기업에서 하루에 처리해야하는 데이터는 시간이 갈수록 기하급수적으로 증가하는데 그렇게하기 위해서는 빠르고 실시간으로 처리되는 요청 처리가 필요하다.
# 현재 통일부 시스템에서 빠르게 데이터 처리가 필요해서 카프카가 필요한 존재라고 인식되지 않지만 암튼 그렇다고 함.
# 넷플릭스Netflix는 전 세계 규모의 네트워크 환경에서 데이터를 수집, 통계, 처리, 적재하기 위한 파이프라인을 연결해주는 역할로 카프카를 사용하고 있다. 또 우버Uber는 탑승자와 운전자의 모바일 앱, GPS, 지도 서비스 등의 데이터 프로듀서로부터 이벤트 데이터를 수집하기 위해 카프카를 사용하였다. 