시나리오: 비트코인API로부터 데이터를 받아 실시간으로 대시보드를 제공할 수있도록 한다.

1. UPbit에서 코인 가격에 대해 API로 제공하고있다.
2. API에 있는 데이터를 받아 Kafka에 넣을 수 있는 Producer를 만들 수 있다.
3. Kafka에서 데이터를 가져가는 Consumer를 만들 수 있다.
4. 스트리밍으로 대시보드를 제공하기 위해 Elastic 스택을 활용할 수 있다.

UPbit API -> Kafka -> Logstash -> Elsticsearch -> Kibana 으로 데이터 파이프라인을 구성

실행순서: 
1. UPbit 회원가입 후 Access, Secret키 발급
2. 코드 실행 
```
    import requests
    import pyupbit
    
    access = "{access_key}"          # 발급받은 access 키 값으로 변경
    secret = "{secret_key}"          # 발급받은 secret 키 값으로 변경
    upbit = pyupbit.Upbit(access, secret)
    
    querystring = {"markets":"KRW-BTC"} #비트코인
    
    url = f"https://api.upbit.com/v1/ticker"
    
    headers = {"accept": "application/json"}
    
    response = requests.get(url, headers=headers, params=querystring)
    
    response.json()
```

3. kafka 설치 (kubernetes에서 동작)
```
    ARGO_PASS=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d); \
    kubectl exec -n argocd $(kubectl get pods -n argocd -o name | grep argocd-server | sed 's%pod/%%') -- \
    sh -c "argocd login argo.cycloudtest.onmetaverses.com --username admin --password $ARGO_PASS --insecure --grpc-web; \
    argocd app create kafka --repo https://github.com/strimzi/strimzi-kafka-operator \
    --server argocd-server \
    --path helm-charts/helm3/strimzi-kafka-operator \
    --dest-server https://kubernetes.default.svc \
    --sync-policy automated \
    -p webhook.enable=true --upsert \
    "
```
4. 토픽 생성
```
    kubectl exec -n kafka my-cluster-kafka-0 -it -- /bin/bash
    cd /bin
    sh kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 3 --topic {topic name} # 생성하고자하는 토픽 명으로 바꿔줌
```

5. producer, comsumer 실행
```
    kubectl -n kafka run kafka-producer -ti --image=quay.io/strimzi/kafka:0.36.1-kafka-3.5.1 --rm=true --restart=Never -- bin/kafka-console-producer.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 --topic {topic name}
    kubectl -n kafka run kafka-consumer -ti --image=quay.io/strimzi/kafka:0.36.1-kafka-3.5.1 --rm=true --restart=Never -- bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 --topic {topic name} --from-beginning
```


