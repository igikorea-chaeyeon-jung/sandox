## 1시간 주기로 기상청 API 에서 받아온 데이터 기반 nifi 수집 파이프라인 테스트

### 결과:

<img width="1434" alt="스크린샷 2023-07-31 오후 5 37 39" src="https://github.com/igikorea-chaeyeon-jung/sandox/assets/133837435/8a4e8724-6a02-4e4b-b0e3-d16628659f73">

### 시나리오:
1. linux 스케줄러를 통해 1시간 단위로 API 데이터 가져와서 SFTP서버에 저장
2. nifi와 SFTP 서버 연동
3. nifi와 HDFS 연동 
4. nifi ListSFTP, FetchSFTP, UpdateAttribute, PutHDFS 프로세서 사용하여 
   가공된 데이터 HDFS에 저장하는 파이프라인 구성
   
### 실행:   
#### 1. nifi 설치
   - nifi 가 돌고있는 pod에 hadoop master node ip에 대한 hostname을 추가해주어야함. '--set sts.hostAliases[0]' 설정 참고
```helm
helm upgrade --install nifi nifi \
  --repo https://cetic.github.io/helm-charts \
  --set auth.admin="CN=admin, OU=NIFI" \
  --set auth.singleUser.username="igichaen" \
  --set auth.singleUser.password="chaeyeonchaeyeon" \
  --set properties.webProxyHost="nifi.cycloudtest.onmetaverses.com" \
  --set replicaCount=1 \
  --set sts.hostAliases[0].ip="<hadoop master node ip>" --set sts.hostAliases[0].hostnames[0]="master01" --set sts.hostAliases[0].hostnames[1]="nn1" \
  --set certManager.enabled=true \
  --set certManager.additionalDnsNames={"nifi.cycloudtest.onmetaverses.com"}
  
kubectl get svc nifi -o yaml | sed "s/port: 8443/port: 443/" - | kubectl replace -f -
kubectl create ingress nifi --class=nginx \
  --rule="nifi.cycloudtest.onmetaverses.com/*=nifi:443,tls" \
  --annotation nginx.ingress.kubernetes.io/backend-protocol="HTTPS"

```
#### 2. nifi 빈 대시보드에서 processor 추가로 ListSFTP, FetchSFTP, UpdateAttribute, PutHDFS 프로세서 추가

#### 3. nifi & FTP 서버 연동
```helm
# password를 통해 접속할 수있도록 설정
  sshd passwd
```
  password 설정했으면 FTP client에서 서버와 연결하듯이 nifi에도 설정정보 입력해주면 됨

  먼저, ListSFTP 프로세서에서 다음과 같이 설정.

  <img width="1438" alt="스크린샷 2023-07-31 오후 4 26 10" src="https://github.com/igikorea-chaeyeon-jung/sandox/assets/133837435/7ada40db-b1c5-48b1-91a5-f7b549562802">

  Hostname, Port, Username, Password 설정

  다음으로, FetchSFTP 프로세서에서 다음과 같이 설정

  <img width="1436" alt="스크린샷 2023-07-31 오후 4 49 29" src="https://github.com/igikorea-chaeyeon-jung/sandox/assets/133837435/5a58e299-5e06-4dee-989d-bb70acd665c1">

  Remote File 설정-> upstream에서 가져온 path 정보 사용

#### 4. nifi & HDFS 연동
  4-1. hadoop 클러스터 구성 > storage/hdfs 파일 참고 
  
   참고 사항 :
   ```
    # hdfs-site.xml에 다음내용추가
      <property>
          <name>dfs.webhdfs.enabled</name>
          <value>true</value>
      </property>
      <property>
          <name>dfs.permissions.enabled</name>
          <value>false</value>
      </property>

```

<img width="1437" alt="스크린샷 2023-07-31 오후 4 26 32" src="https://github.com/igikorea-chaeyeon-jung/sandox/assets/133837435/5f1af8c9-1a65-4d1a-a3f8-e4a071e8ad1c">
  
  4-2. nifi에서 hdfs 구성 파일 추가
    Hadoop Configuration Resources에 hdfs 설정파일을 넣어줘야 nifi가 hadoop을 인식할 수있음, 위 경로는 nifi pod 내부 로컬 경로이기때문에 해당경로에 hdfs-site.xml과
    core-site.xml을 넣어주어야함

  nifi pod이 돌고있는 호스트 서버 특정경로(/usr/local/ect/)하위에 hdfs-site.xml, core-site.xml 을 넣어두고 pod 내 특정경로(/opt/nifi/flow) 하위에 복사
    ** 특정경로는 바뀌어도 됨

 ```   
    kubectl cp /usr/local/etc/hdfs-site.xml nifi-0:/opt/nifi/flow
    kubectl cp /usr/local/etc/core-site.xml nifi-0:/opt/nifi/flow
 ```

  5. 프로세서들 재생버튼 클릭

  6. hdfs에 저장된 데이터 확인
     
  <img width="1435" alt="스크린샷 2023-07-31 오후 5 36 26" src="https://github.com/igikorea-chaeyeon-jung/sandox/assets/133837435/3dfb47f5-7cff-4df4-b384-68fcfbe23a1c">
